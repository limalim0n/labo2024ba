{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727bcbdf-4dba-44a5-84cf-855b67ec995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "import warnings\n",
    "import logging\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_optimizer as optim_mod\n",
    "\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from torch.nn.modules.transformer import TransformerEncoderLayer, TransformerEncoder\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "from IPython.display import Javascript, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e417d0-66bd-4054-a415-5ae0310ad74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose Model\n",
    "useTRANSFORMERS = True\n",
    "useLSTM = False\n",
    "useLSTMAttention = False\n",
    "useLSTMWeightAtention = False\n",
    "useLSTMEncoder = False\n",
    "\n",
    "variables = {\n",
    "    'useTRANSFORMERS': useTRANSFORMERS,\n",
    "    'useLSTM': useLSTM,\n",
    "    'useLSTMAttention': useLSTMAttention,\n",
    "    'useLSTMWeightAtention': useLSTMWeightAtention,\n",
    "    'useLSTMEncoder': useLSTMEncoder\n",
    "}\n",
    "true_model = [var_name for var_name, var_value in variables.items() if var_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d00f4b0-a0e0-4994-88e0-85933227f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryPositionalEmbeddingROPE(nn.Module):\n",
    "    def __init__(self, dim, base=10000):\n",
    "        super(RotaryPositionalEmbeddingROPE, self).__init__()\n",
    "        if dim % 2 != 0:\n",
    "            raise ValueError(\"The dimension for RoPE must be even.\")\n",
    "        self.dim = dim\n",
    "        self.base = base\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_heads, seq_len, head_dim = x.size()\n",
    "        device = x.device\n",
    "        position_ids = torch.arange(seq_len, dtype=torch.float, device=device).unsqueeze(0).unsqueeze(2)\n",
    "        dim_t = torch.arange(0, head_dim, 2, dtype=torch.float, device=device)\n",
    "        dim_t = self.base ** (-dim_t / head_dim)\n",
    "        angles = position_ids * dim_t\n",
    "        sin_angles = angles.sin().unsqueeze(0).unsqueeze(2)\n",
    "        cos_angles = angles.cos().unsqueeze(0).unsqueeze(2)\n",
    "        x1, x2 = x[..., 0::2], x[..., 1::2]\n",
    "        x_rotated = torch.cat([x1 * cos_angles - x2 * sin_angles,\n",
    "                               x1 * sin_angles + x2 * cos_angles], dim=-1)\n",
    "        return x_rotated\n",
    "\n",
    "class MultiheadAttentionWithRoPE(nn.MultiheadAttention):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.1, bias=True, add_bias_kv=False,\n",
    "                 add_zero_attn=False, kdim=None, vdim=None, base=10000, batch_first=True):\n",
    "        super(MultiheadAttentionWithRoPE, self).__init__(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            bias=bias,\n",
    "            add_bias_kv=add_bias_kv,\n",
    "            add_zero_attn=add_zero_attn,\n",
    "            kdim=kdim,\n",
    "            vdim=vdim,\n",
    "            batch_first=batch_first\n",
    "        )\n",
    "        self.rotary_emb = RotaryPositionalEmbeddingROPE(self.head_dim, base=base)\n",
    "\n",
    "    def forward(self, query, key, value, key_padding_mask=None, attn_mask=None, need_weights=True,\n",
    "                average_attn_weights=True, is_causal=False, **kwargs):\n",
    "        if self.batch_first:\n",
    "            Q = query.view(query.size(0), query.size(1), self.num_heads, self.head_dim).transpose(1,2)\n",
    "            K = key.view(key.size(0), key.size(1), self.num_heads, self.head_dim).transpose(1,2)\n",
    "            Q = self.rotary_emb(Q)\n",
    "            K = self.rotary_emb(K)\n",
    "            Q = Q.transpose(1,2).contiguous().view(query.size(0), query.size(1), self.embed_dim)\n",
    "            K = K.transpose(1,2).contiguous().view(key.size(0), key.size(1), self.embed_dim)\n",
    "        else:\n",
    "            raise NotImplementedError(\"batch_first=False is not supported in this custom attention.\")\n",
    "        attn_output, attn_weights = super(MultiheadAttentionWithRoPE, self).forward(\n",
    "            Q, K, value, key_padding_mask=key_padding_mask, attn_mask=attn_mask,\n",
    "            need_weights=need_weights, average_attn_weights=average_attn_weights\n",
    "        )\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "class TransformerEncoderLayerWithRoPE(TransformerEncoderLayer):\n",
    "    def __init__(self, embed_dim, num_heads, dim_feedforward=2048, dropout=0.1, base=10000, activation='relu', batch_first=True):\n",
    "        super(TransformerEncoderLayerWithRoPE, self).__init__(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "            batch_first=batch_first\n",
    "        )\n",
    "        self.self_attn = MultiheadAttentionWithRoPE(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            base=base,\n",
    "            batch_first=batch_first\n",
    "        )\n",
    "\n",
    "class ActorCriticOrdinalTransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=512, num_heads=8, num_layers=6, \n",
    "                 dim_feedforward=2048, dropout=0.2, num_actor_heads=10, \n",
    "                 num_classes=5, base=10000):\n",
    "        super(ActorCriticOrdinalTransformerModel, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_thresholds = num_classes - 1\n",
    "        \n",
    "        # Input projection\n",
    "        self.linear_proj = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Actor Transformer Encoder with RoPE\n",
    "        actor_encoder_layer = TransformerEncoderLayerWithRoPE(\n",
    "            embed_dim=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            base=base,\n",
    "            activation='relu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.actor_transformer_encoder = TransformerEncoder(actor_encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Actor Heads\n",
    "        self.actor_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(d_model, dim_feedforward),\n",
    "                nn.LeakyReLU(negative_slope=0.01),\n",
    "                nn.LayerNorm(dim_feedforward),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(dim_feedforward, d_model),\n",
    "                nn.LeakyReLU(negative_slope=0.01),\n",
    "                nn.LayerNorm(d_model),\n",
    "                nn.Linear(d_model, self.num_thresholds)  # Output logits for thresholds\n",
    "            )\n",
    "            for _ in range(num_actor_heads)\n",
    "        ])\n",
    "        \n",
    "        # Learnable Raw Thresholds (before ordering)\n",
    "        # Initialize raw thresholds; values will be transformed to ensure ordering\n",
    "        self.raw_thresholds = nn.Parameter(torch.linspace(-1, 1, steps=self.num_thresholds))\n",
    "    \n",
    "    def forward(self, src, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: [batch_size, seq_len, input_dim]\n",
    "            src_key_padding_mask: [batch_size, seq_len]\n",
    "        \n",
    "        Returns:\n",
    "            action_probs: [batch_size, seq_len, K-1] (Cumulative Probabilities)\n",
    "        \"\"\"\n",
    "        # Project input to model dimension\n",
    "        src = self.linear_proj(src)  # [batch_size, seq_len, d_model]\n",
    "        \n",
    "        # Actor Transformer Encoding\n",
    "        actor_transformer_output = self.actor_transformer_encoder(\n",
    "            src, src_key_padding_mask=src_key_padding_mask\n",
    "        )  # [batch_size, seq_len, d_model]\n",
    "        \n",
    "        # Actor Heads Processing\n",
    "        actor_outputs = [actor_head(actor_transformer_output) for actor_head in self.actor_heads]\n",
    "        actor_outputs = torch.stack(actor_outputs, dim=0)  # [num_actor_heads, batch_size, seq_len, K-1]\n",
    "        action_preds = actor_outputs.mean(dim=0)  # [batch_size, seq_len, K-1]\n",
    "        \n",
    "        # Ordering and Applying Thresholds\n",
    "        # Apply softplus to raw thresholds to ensure positivity, then cumulative sum to ensure ordering\n",
    "        thresholds = torch.cumsum(F.softplus(self.raw_thresholds), dim=0)  # [K-1]\n",
    "        thresholds = thresholds.unsqueeze(0).unsqueeze(0)  # [1, 1, K-1]\n",
    "        \n",
    "        # Compute Cumulative Probabilities using CLM\n",
    "        # P(Y <= k | X) = sigmoid(logit(Y <= k | X) - theta_k)\n",
    "        cumulative_probs = torch.sigmoid(action_preds - thresholds)  # [batch_size, seq_len, K-1]\n",
    "        \n",
    "        # Assertions to ensure correct output shapes\n",
    "        assert cumulative_probs.shape[-1] == self.num_thresholds, \\\n",
    "            f\"Expected cumulative_probs to have last dimension {self.num_thresholds}, but got {cumulative_probs.shape[-1]}\"\n",
    "        \n",
    "        return cumulative_probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6504c412-bc81-4c6e-8b87-e111c65a3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(input_seq, pad_token=0):\n",
    "    # Returns True for padding positions, False for valid positions\n",
    "    mask = (input_seq == pad_token).all(dim=-1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "108086fe-d89b-442f-83f4-686bb3ef896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_labels(action_probs, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Convert threshold probabilities to class labels.\n",
    "\n",
    "    Args:\n",
    "        action_probs (torch.Tensor): Probabilities for each ordinal threshold.\n",
    "                                     Shape: [batch_size, seq_len, K-1]\n",
    "        threshold (float): Probability threshold to determine class boundaries.\n",
    "\n",
    "    Returns:\n",
    "        class_labels (torch.Tensor): Predicted class indices.\n",
    "                                     Shape: [batch_size, seq_len]\n",
    "    \"\"\"\n",
    "    # Compare probabilities against the threshold\n",
    "    exceeded = (action_probs > threshold).int()  # [batch_size, seq_len, K-1]\n",
    "\n",
    "    # Sum the number of exceeded thresholds to get class labels\n",
    "    class_labels = exceeded.sum(dim=-1)  # [batch_size, seq_len]\n",
    "\n",
    "    # Clamp class_labels to be within [0, K-1]\n",
    "    class_labels = torch.clamp(class_labels, 0, action_probs.size(-1))\n",
    "\n",
    "    return class_labels\n",
    "\n",
    "def get_class_labels_best(action_probs, thresholds):\n",
    "    \"\"\"\n",
    "    Convert threshold probabilities to class labels using thresholds per class boundary.\n",
    "\n",
    "    Args:\n",
    "        action_probs (torch.Tensor): Probabilities for each ordinal threshold.\n",
    "                                     Shape: [batch_size, seq_len, K-1]\n",
    "        thresholds (float or list or torch.Tensor): Thresholds for each class boundary.\n",
    "                                                    Shape: [K-1]\n",
    "\n",
    "    Returns:\n",
    "        class_labels (torch.Tensor): Predicted class indices.\n",
    "                                     Shape: [batch_size, seq_len]\n",
    "    \"\"\"\n",
    "    # Ensure thresholds is a torch tensor\n",
    "    if not isinstance(thresholds, torch.Tensor):\n",
    "        thresholds = torch.tensor(thresholds, device=action_probs.device, dtype=action_probs.dtype)\n",
    "    else:\n",
    "        thresholds = thresholds.to(action_probs.device).type_as(action_probs)\n",
    "\n",
    "    # Reshape thresholds for broadcasting\n",
    "    thresholds = thresholds.view(1, 1, -1)  # Shape: [1, 1, K-1]\n",
    "\n",
    "    # Compare probabilities against thresholds\n",
    "    exceeded = (action_probs > thresholds).int()  # Shape: [batch_size, seq_len, K-1]\n",
    "\n",
    "    # Sum the number of thresholds exceeded to get class labels\n",
    "    class_labels = exceeded.sum(dim=-1)  # Shape: [batch_size, seq_len]\n",
    "\n",
    "    # Clamp class_labels to be within [0, K]\n",
    "    class_labels = torch.clamp(class_labels, 0, action_probs.size(-1))\n",
    "\n",
    "    return class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86260652-dbb3-4be8-b18a-70a50c498391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the sequences and labels arrays\n",
    "loaded_data_sequences = np.load('sequence_array_filtered_INFERENCE_final.npz', allow_pickle=True)\n",
    "loaded_data_labels = np.load('label_array_filtered_INFERENCE.npz', allow_pickle=True)\n",
    "\n",
    "# Access the saved arrays\n",
    "sequence_array = loaded_data_sequences['sequences']\n",
    "label_array = loaded_data_labels['labels']\n",
    "label_array = label_array[:, :, :-2]  # Remove the last two timesteps from the label array\n",
    "\n",
    "print(\"Array loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b403f176-1754-4157-bce6-afd54d5affe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165093, 1, 31)\n",
      "(165093, 33, 307)\n"
     ]
    }
   ],
   "source": [
    "print(label_array.shape[:])\n",
    "print(sequence_array.shape[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a53238-1b5f-4cb4-8b16-83ce33a08823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91377c3b-33ee-4406-9af0-9686fd277179",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_de_cliente = sequence_array[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1813e3-55eb-4136-8150-7bec71167a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.91837330e+07, 2.91844680e+07, 2.91852450e+07, ...,\n",
       "       1.88122277e+08, 1.88128903e+08, 1.88136205e+08])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numero_de_cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe603de-e446-4a5c-982a-8dd1e27ab879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165093, 33, 306)\n"
     ]
    }
   ],
   "source": [
    "sequence_array = sequence_array[:, :, 1:]  # Remove client ID (first feature)\n",
    "print(sequence_array.shape[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e77ef2c-b8e4-4e45-97ac-b5c4cd113522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d27694ea-4271-4bc8-8cb1-fad5393303c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Classes: ['BAJA+1' 'BAJA+2' 'CONTINUA' 'OUT']\n"
     ]
    }
   ],
   "source": [
    "# Initialize a LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Flatten the label array and encode the labels as integers\n",
    "label_array_flat = label_array.flatten()  # Flattening the array for label encoding\n",
    "label_array_encoded = label_encoder.fit_transform(label_array_flat)\n",
    "\n",
    "# Reshape it back to the original shape after encoding\n",
    "label_array_encoded = label_array_encoded.reshape(label_array.shape)\n",
    "\n",
    "# Print encoded classes for verification\n",
    "class_names = label_encoder.classes_\n",
    "print(f\"Encoded Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66986333-f45b-488e-bca8-0c34ba827a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165093, 1, 31)\n"
     ]
    }
   ],
   "source": [
    "print(label_array_encoded.shape[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e6a7249-204b-47b0-8a5d-0a48de90c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params={'lr': 1e-07, 'dropout': 0.1, 'batch_size': 500, 'num_layers': 8, 'd_model': 420, \n",
    "         'weight_baja1': 60, 'weight_baja2': 70, 'weight_continua': 1, \n",
    "         'weight_decay': 5e-5, 'dim_feedforward': 1000, 'beta1': 0.93, 'beta2': 0.97, \n",
    "         'eps': 2.1e-06, 'grad_clip': 0.69, 'gamma': 4.0, 'reward_baja_2': 117, \n",
    "         'penalty_baja_2': -3, 'miss_baja_2_penalty': -100, 'scheduler_patience': 2, 'scheduler_factor': 0.69, \n",
    "         'num_heads': 10, 'factor': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a561346-d1bc-4811-a5ae-61b1eeb936c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 306\n",
    "num_classes = 5\n",
    "num_heads = 4 \n",
    "d_model = Params['d_model']    \n",
    "dim_feedforward=Params['dim_feedforward'] \n",
    "dropout = Params['dropout']\n",
    "num_layers = Params['num_layers']\n",
    "\n",
    "num_heads = Params['num_heads']\n",
    "factor = Params['factor']\n",
    "d_model = num_heads * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37963027-5dae-424c-9286-f250e446d4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using: \" + device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92423420-7331-4805-adf7-5cb84268bc6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_297017/573050527.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'best_model_threshold_ganancia_[].pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ActorCriticOrdinalTransformerModel(\n",
       "  (linear_proj): Linear(in_features=306, out_features=512, bias=True)\n",
       "  (actor_transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayerWithRoPE(\n",
       "        (self_attn): MultiheadAttentionWithRoPE(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          (rotary_emb): RotaryPositionalEmbeddingROPE()\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (actor_heads): ModuleList(\n",
       "    (0-9): 10 x Sequential(\n",
       "      (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (7): Linear(in_features=512, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights_vector = [Params['weight_baja1'] , Params['weight_baja2'] , Params['weight_continua']]\n",
    "class_weights = torch.tensor(class_weights_vector, dtype=torch.float32).to(device)\n",
    "\n",
    "model = ActorCriticOrdinalTransformerModel(\n",
    "    input_dim=input_dim,  # Replace with your input dimension\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    num_layers=6,\n",
    "    dim_feedforward=2048,\n",
    "    dropout=0.2,\n",
    "    num_actor_heads=10,\n",
    "    num_classes=5,\n",
    "    base=10000\n",
    ")\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(f'best_model_threshold_ganancia_[].pth')) \n",
    "model = model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebe5c5f8-da0e-4a30-a53d-1d3d26f2e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_tensor = torch.tensor(sequence_array, dtype=torch.float32).squeeze(1).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ab95c9b-0ef4-41c6-ae51-43ee132e17a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([165093, 33, 306])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "184e6055-5e66-4103-81f9-ac30c027f21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████████████████████████| 323/323 [00:32<00:00,  9.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define batch size\n",
    "batch_size = 512\n",
    "\n",
    "# Prepare DataLoader for the sequence_tensor\n",
    "test_dataset = TensorDataset(sequence_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize lists to collect the predictions\n",
    "all_probs_last = []\n",
    "\n",
    "# Disable gradient calculation for inference\n",
    "with torch.no_grad():\n",
    "    progress_bar = tqdm(test_loader, desc=\"Inference\", leave=True)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Extract the sequences from the batch and move to device\n",
    "        X_test_batch = batch[0].to(device)\n",
    "\n",
    "        # Create the key padding mask for the test data\n",
    "        src_key_padding_mask = create_padding_mask(X_test_batch, pad_token=0).to(device)\n",
    "\n",
    "        # Forward pass: Get model predictions\n",
    "        #outputs = model(X_test_batch, src_key_padding_mask)\n",
    "\n",
    "        #outputs, critic_outputs = model(X_test_batch, src_key_padding_mask) \n",
    "        #actions_taken, action_probs, state_values = model(X_test_batch, src_key_padding_mask)\n",
    "        action_preds = model(X_test_batch, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            #predicted_labels = get_class_labels(action_preds, threshold=0.5)\n",
    "            predicted_labels = get_class_labels_best(action_preds, thresholds=[(0.08499999999999999, 0.16000000000000011, 0.16000000000000011, 0.55)])\n",
    "\n",
    "        last_timestep_probs = predicted_labels[:, -1].cpu().numpy()\n",
    "\n",
    "        # Get probabilities for the last timestep\n",
    "        #last_timestep_probs = torch.softmax(outputs[:, -1, :], dim=-1).cpu().numpy()  # Shape: [batch_size, num_classes]\n",
    "        #last_timestep_probs = torch.softmax(action_preds[:, -1, :], dim=-1).cpu().numpy()  # Shape: [batch_size, num_classes]\n",
    "\n",
    "        # Collect predicted probabilities for the last timestep\n",
    "        all_probs_last.append(last_timestep_probs)\n",
    "\n",
    "all_probs_last = np.concatenate(all_probs_last, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2edf0936-9b73-4db0-b38c-51efb9fe7dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Class Counts (Predicted for Last Timestep):\n",
      "BAJA+1 (0): 0\n",
      "BAJA+2 (1): 9526\n",
      "BAJA+3 (2): 273\n",
      "BAJA+4 (3): 2694\n",
      "CONTINUA (4): 152600\n",
      "OUT (5): 0\n"
     ]
    }
   ],
   "source": [
    "class_labels_list = [0, 1, 2, 3, 4, 5]\n",
    "target_names = ['BAJA+1', 'BAJA+2', 'BAJA+3', 'BAJA+4', 'CONTINUA', 'OUT']\n",
    "\n",
    "class_counts = Counter(all_probs_last)\n",
    "print(\"\\nFinal Class Counts (Predicted for Last Timestep):\")\n",
    "for class_value, class_name in zip(class_labels_list, target_names):\n",
    "    count = class_counts.get(class_value, 0)\n",
    "    print(f\"{class_name} ({class_value}): {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72d82b33-a5c5-4bbc-a893-574a673f48f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Class Counts (Predicted for Last Timestep):\n",
      "BAJA+1 (0): 152873\n",
      "BAJA+2 (1): 12220\n",
      "BAJA+3 (2): 0\n",
      "BAJA+4 (3): 0\n",
      "CONTINUA (4): 0\n",
      "OUT (5): 0\n"
     ]
    }
   ],
   "source": [
    "y_pred = all_probs_last\n",
    "\n",
    "# Convert 2 (CONTINUA) and 3 (OUT) to 0 (BAJA+1)\n",
    "#y_pred_converted = np.where((y_pred == 0) , 1, y_pred)\n",
    "#y_pred_converted = np.where((y_pred_converted == 2) , 0, y_pred_converted)\n",
    "\n",
    "y_pred_converted = np.where((y_pred == 2) , 0, y_pred)\n",
    "y_pred_converted = np.where((y_pred_converted == 3) , 1, y_pred_converted)\n",
    "y_pred_converted = np.where((y_pred_converted == 4) , 0, y_pred_converted)\n",
    "\n",
    "\n",
    "#y_pred_converted = np.where((y_pred == 2) | (y_pred == 3), 0, y_pred)\n",
    "#y_pred_converted = np.where((y_pred == 1) | (y_pred == 2) | (y_pred == 3), 5, y_pred)\n",
    "#y_pred_converted = np.where((y_pred_converted == 0) , 1, y_pred_converted)\n",
    "#y_pred_converted = np.where((y_pred_converted == 5) , 0, y_pred_converted)\n",
    "\n",
    "# Check the new class distribution after conversion\n",
    "class_counts_converted = Counter(y_pred_converted)\n",
    "\n",
    "class_labels_list = [0, 1, 2, 3, 4, 5]\n",
    "target_names = ['BAJA+1', 'BAJA+2', 'BAJA+3', 'BAJA+4', 'CONTINUA', 'OUT']\n",
    "\n",
    "class_counts = Counter(y_pred_converted)\n",
    "print(\"\\nFinal Class Counts (Predicted for Last Timestep):\")\n",
    "for class_value, class_name in zip(class_labels_list, target_names):\n",
    "    count = class_counts.get(class_value, 0)\n",
    "    print(f\"{class_name} ({class_value}): {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aef6b6ad-0574-466e-9822-fa32c49cb615",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_converted = y_pred_converted.astype(int)\n",
    "numero_de_cliente_flat = numero_de_cliente.flatten()\n",
    "numero_de_cliente_flat = numero_de_cliente_flat.astype(int)\n",
    "submission_df = pd.DataFrame({\n",
    "    'numero_de_cliente': numero_de_cliente_flat,\n",
    "    'Predicted': y_pred_converted\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2d388f4-077d-48e1-a776-44ac2e5a4ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission file...\n",
      "Submission file saved as 'submissionNoForce.csv'\n"
     ]
    }
   ],
   "source": [
    "# Ensure the submission file has exactly 165,093 rows (as specified in your requirements)\n",
    "assert submission_df.shape[0] == 165093, \"The submission file must have exactly 165,093 rows.\"\n",
    "\n",
    "# Save the first submission file\n",
    "print(\"Saving submission file...\")\n",
    "submission_df.to_csv('submissionNoForce.csv', index=False)\n",
    "print(\"Submission file saved as 'submissionNoForce.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b7dca31-6e8b-48fb-8820-daeba210639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip done\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# Compress the submission.csv file\n",
    "with open('submissionNoForce.csv', 'rb') as f_in:\n",
    "    with gzip.open('submissionNoForce.csv.gz', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(\"gzip done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ed3a6-e5e6-4af3-9b1e-6cfc05165c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2915be2f-b783-4f63-aa21-95f36fdf8dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
